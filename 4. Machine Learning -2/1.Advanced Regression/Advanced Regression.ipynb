{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "serious-wichita",
   "metadata": {},
   "source": [
    "#### Identifying Nonlinearity in Data\n",
    "\n",
    "The linear regression model assumes that there is a linear relationship between the predictors and the response variable. However, if the true relationship is nonlinear, then virtually all of the conclusions that we draw from the fit do not hold much credibility. In addition, the prediction accuracy of the model can be reduced significantly. In the forthcoming video, Anjali explains how we can identify nonlinearity in data.\n",
    "\n",
    "1.<b> For Simple Linear Regression: </b>\n",
    "      Plot the independent variable against the dependent variable to check for nonlinear patterns.\n",
    "\n",
    "2.<b> For Multiple Linear Regression </b>, since there are multiple predictors, we, instead, plot the residuals versus the predicted values.Ideally, the residual plot will show no observable pattern. In case a pattern is observed, it may indicate a problem with some aspect of the linear model. Apart from that:\n",
    "    1. Residuals should be randomly scattered around 0.\n",
    "    2. The spread of the residuals should be constant.\n",
    "    3. There should be no outliers in the data\n",
    "    4. Bimodal distribution\n",
    "    \n",
    "If nonlinearity is present, then we may need to plot each predictor against the residuals to identify which predictor is nonlinear.\n",
    "\n",
    "https://www.mathsisfun.com/sets/functions-common.html\n",
    "\n",
    "There are three methods to handle nonlinear data:\n",
    "1. Polynomial regression\n",
    "2. Data transformation\n",
    "3. Nonlinear regression\n",
    "\n",
    "\n",
    "1. <b> Polynomial Regression </b>: \n",
    "   The kth-order polynomial model in one variable is given by:\n",
    "   \n",
    "   $ y = {\\beta}_{0}  + {\\beta}_{1} x + {\\beta}_{2} x^{2}+ ..... + {\\beta}_{k} x^{k}  + {\\epsilon} $\n",
    "\n",
    "Depending upon the shape of the residual to pred value distribution. Replace the issue feature with polynomial predictor like if the scatter plot is parabola. Create a new feature with square calculation. <b> In polynomial regression, we need to include the lower degree polynomials in the model as well </b>\n",
    "Ex: the scatter plot is:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "predictors would you include $ a, a^2,a^3 $ and linear regression equation will be :\n",
    "\n",
    "  $ y = {\\beta}_{0}  + {\\beta}_{1} x + {\\beta}_{2} x^{2} + {\\beta}_{3} x^{3} + {\\epsilon} $\n",
    "  \n",
    "2. <b> Data Transformation </b>\n",
    "If the residual plot indicates the presence of nonlinear relations in the data, then a simple approach is to use nonlinear transformations of the predictors. For instance, for a predictor x, these transformations can be log(x), sqrt(x), exp(x), etc., in the regression model.\n",
    "\n",
    "We need to remember that although log is the most commonly used function for transformations, it is not the only one that we can use. There are a few other functions that we can use depending upon the shape of the data.\n",
    "\n",
    "$ {\\log}y = {\\beta}_{0}  + {\\beta}_{1} x + {\\beta}_{2} x^{2} + {\\beta}_{3} x^{3} + {\\epsilon} $\n",
    "\n",
    "<b> How do we decide when and what to transform? </b>\n",
    "\n",
    "Essentially, to handle nonlinear data, we may have to try different transformations on the data to determine a model that fits it well. Hence, we may try polynomial models or transformations of the x-variable(s) or the y-variable, or both. These transformations can be square root, logarithmic or reciprocal transformations, although this is not an exhaustive list.\n",
    "\n",
    "        A. When the predictor variables are non-linear with the response variable then transform the predictor variable\n",
    "        B. When the problem is non-normality of error terms or residuals and unequal variance , then consider the transformation of the response variable(this can also help with non-linearity).\n",
    "        C. When the regression function is non-linear and non-normality of error terms or residuals and unequal variance is also there, then consider transformation of both response variable and predictor variable.\n",
    "        \n",
    "Polynomial regression and data transformation allow us to stay within the linear regression framework. After transforming the predictors, when we fit the model, we still check whether the model follows the assumptions so that we can trust the results that we get from the model.\n",
    "\n",
    "3. <b> Non-Linear Regression: </b>\n",
    "All of the models that we have discussed so far have been linear in terms of the parameters (i.e., linear in terms of the beta's). Nevertheless, for models in which the response variable is related nonlinearly with the parameters or the model coefficients, we use nonlinear regression\n",
    "\n",
    "$ y = {\\beta}_{1}  / 1+ {e}^({\\beta}_{2} + {\\beta}_{3} x_{i}) + {\\epsilon} $\n",
    "\n",
    "\n",
    "When we fit a linear regression model to a particular data set, many problems may arise. Most common among these are the following:\n",
    "\n",
    "1. Non-constant variance\n",
    "\n",
    "Constant variance of error terms is one of the assumptions of linear regression. Unfortunately, many times, we observe non-constant error terms. As discussed earlier, as we move from left to right on the residual plots, the variances of the error terms may show a steady increase or decrease. This is also termed as heteroscedasticity.\n",
    "\n",
    "When faced with this problem, one possible solution is to transform the response Y using a function such as log or the square root of the response value. Such a transformation results in a greater amount of shrinkage of the larger responses, leading to a reduction in heteroscedasticity.\n",
    "\n",
    " \n",
    "2. Autocorrelation\n",
    "\n",
    "This happens when data is collected over time and the model fails to detect any time trends. Due to this, errors in the model are correlated positively over time, such that each error point is more similar to the previous error. This is known as autocorrelation, and it can sometimes be detected by plotting the model residuals versus time. Such correlations frequently occur in the context of time series data, which consists of observations for which measurements are obtained at discrete points in time.\n",
    " \n",
    "In order to determine whether this is the case for a given data set, we can plot the residuals from our model as a function of time. If the errors are uncorrelated, then there should be no observable pattern. However, on the other hand, if the consecutive values appear to follow each other closely, then we may want to try an autoregression model. \n",
    "\n",
    " \n",
    "\n",
    "3. Multicollinearity\n",
    "\n",
    "If two or more of the predictors are linearly related to each other when building a model, then these variables are considered multicollinear. A simple method to detect collinearity is to look at the correlation matrix of the predictors. In this correlation matrix, if we have a high absolute value for any two variables, then they can be considered highly correlated. A better method to detect multicollinearity is to calculate the variance inflation factor (VIF), which you studied in the Linear Regression module.\n",
    "\n",
    "When faced with the problem of collinearity, we can try a few different approaches. One is to drop one of the problematic variables from the regression model. The other is to combine the collinear variables together into a single predictor. Regularization (which we will discuss in the next session) helps here as well.\n",
    "\n",
    "4. Overfitting\n",
    "\n",
    "When a model is too complex, it may lead to overfitting. It means the model may produce good training results but would fail to perform well on the test data. One possible solution for overfitting is to increase the amount and diversity of the training data. Another solution is regularization, which we will cover in the next session. \n",
    "\n",
    "5. Extrapolation\n",
    "\n",
    "Extrapolation occurs when we use a linear regression model to make predictions for predictor values that are not present in the range of data used to build the model. For instance, suppose we have built a model to predict the weight of a child given its height, which ranges from 3 to 5 feet. If we now make predictions for a child with height greater than 5 feet or less than 3 feet, then we may get incorrect predictions. The predictions are valid only within the range of values that are used for building the model. Hence, we should not extrapolate beyond the scope of the model.\n",
    "\n",
    "#### Regularisation\n",
    "\n",
    "When a model performs really well on the data that is used to train it, but does not perform well with unseen data, we know we have a problem: overfitting. Such a model will perform very well with training data and, hence, will have very low bias; but since it does not perform well with unseen data, it will show high variance. \n",
    "\n",
    "In other words, bias in a model is high when it does not perform well on the training data itself, and variance is high when the model does not perform well on the test data. Please note that a model failing to fit on the test data means that the model results on the test data varies a lot as the training data changes. This may be because the model coefficients do not have high reliability.\n",
    "\n",
    "There is a trade-off between bias and variance with respect to model complexity. A simple model would usually have high bias and low variance, whereas a complex model would have low bias and high variance. In either case, the total error would be high.\n",
    "\n",
    "What we need is lowest total error, i.e., low bias and low variance, such that the model identifies all the patterns that it should and is also able to perform well with unseen data.\n",
    " \n",
    "\n",
    "For this, we need to manage model complexity: It should neither be too high, which would lead to overfitting, nor too low, which would lead to a model with high bias (a biased model) that does not even identify necessary patterns in the data.\n",
    "\n",
    "Regularization helps with managing model complexity by essentially shrinking the model coefficient estimates towards 0. This discourages the model from becoming too complex, thus avoiding the risk of overfitting.\n",
    "\n",
    "Model Complexity depends on:\n",
    "\n",
    "1. No of coefficients\n",
    "2. Magnitude of coefficients\n",
    "\n",
    "Cost = RSS + Penality\n",
    "\n",
    "When building an OLS model, we want to estimate the coefficients for which the cost/loss, i.e., RSS, is minimum. Optimising this cost function results in model coefficients with the least possible bias, although the model may have overfitted and hence have high variance. \n",
    "\n",
    "In case of overfitting, we know that we need to manage the model’s complexity by primarily taking care of the magnitudes of the coefficients. The more extreme values of the coefficients are (high positive or negative values of the coefficients), the more complex the model is and, hence, the higher are the chances of overfitting.\n",
    "\n",
    "When we use regularization, we add a penalty term to the model’s cost function\n",
    "\n",
    "Here, the cost function would be Cost = RSS + Penalty.\n",
    " \n",
    "Adding this penalty term in the cost function helps suppress or shrink the magnitude of the model coefficients towards 0. This discourages the creation of a more complex model, thereby preventing the risk of overfitting.\n",
    " \n",
    "When we add this penalty and try to get the model parameters that optimise this updated cost function (RSS + Penalty), the coefficients that we get given the training data may not be the best (maybe more biased). Although with this minor compromise in terms of bias, the variance of the model may see a marked reduction. Essentially, with regularization, we compromise by allowing a little bias for a significant gain in variance. \n",
    "\n",
    "We also need to remember two points about the model coefficients that we obtain from OLS:\n",
    "\n",
    "1. These coefficients can be highly unstable – this can happen when only a few of the predictors that we have considered to build our model are related significantly to the response variable and the rest are not very helpful, hence random variables.\n",
    "\n",
    "2. There may be a large variability in the model coefficients due to these unrelated random variables such that even a small change in the training data may lead to a large variance in the model coefficients. Such model coefficients are no longer reliable, since we may get different coefficient values each time we retrain the model.\n",
    "\n",
    "3. Multicollinearity, i.e., the presence of highly correlated predictors, may be another reason for the variability of model coefficients. Regularization helps here as well.\n",
    "\n",
    "<b>To Summarize, we use regularization because we want our models to work well with unseen data, without missing out on identifying underlying patterns in the data. For this, we are willing to make a compromise by allowing a little bias for a significant reduction in variance. We also understood that the more extreme the values of the model coefficients are, the higher are the chances of model overfitting. Regularization prevents this by shrinking the coefficients towards 0. In the next two segments, we will discuss the two techniques of regularization: Ridge and Lasso and understand how the penalty term helps with the shrinkage.</b>\n",
    "\n",
    "<b> Ridge Regression </b>\n",
    "\n",
    "Cost function for OLS: $ \\sum \\limits_{i=1} ^{n} (y_{i} - \\hat{y}_{i})^2 $\n",
    "\n",
    "Cost function for Ridge: $ \\sum \\limits_{i=1} ^{n} (y_{i} - \\hat{y}_{i})^2 + {\\lambda} \\sum \\limits_{j=1} ^{p} {\\beta}^2_{j} $\n",
    "\n",
    "In OLS, we get the best coefficients by minimising the residual sum of squares (RSS). Similarly, with Ridge regression also, we estimate the model coefficients, but by minimising a different cost function. This cost function adds a penalty term to the RSS. The penalty term is lambda multiplied by the sum of squared model coefficients. In the cost function, the penalty term, also called the shrinkage penalty, would be small only if the coefficients are small, i.e., close to 0. Hence, while fitting the Ridge regression model, since we need to find out the model coefficients that minimize the entire cost, i.e., RSS and a penalty, it would have the effect of shrinking the model coefficients, i.e., the betas, towards 0.\n",
    "\n",
    "Now, what is the role of lambda here? It is hypertuning paramter. It regularises the model. If lambda is 0, then the cost function would not contain the penalty term and there will be no shrinkage of the model coefficients. They would be the same as those from OLS. However, since lambda moves towards higher values, the shrinkage penalty increases, pushing the coefficients further towards 0, which may lead to model underfitting. Choosing an appropriate lambda becomes crucial: If it is too small, then we would not be able to solve the problem of overfitting, and with too large a lambda, we may actually end up underfitting.\n",
    " \n",
    "\n",
    "Another point to note is that in OLS, we will get only one set of model coefficients when the RSS is minimised. However, in Ridge regression, for each value of lambda, we will get a different set of model coefficients.\n",
    "<b>\n",
    "to summarise:\n",
    "\n",
    "1. Ridge regression has a particular advantage over OLS when the OLS estimates have high variance, i.e., when they overfit. Regularization can significantly reduce model variance while not increasing bias much. \n",
    "\n",
    "2. The tuning parameter lambda helps us determine how much we wish to regularize the model. The higher the value of lambda, the lower the value of the model coefficients, and more is the regularization. \n",
    "\n",
    "3. Choosing the right lambda is crucial so as to reduce only the variance in the model, without compromising much on identifying the underlying patterns, i.e., the bias.  A large lambda implies a simpler model. Therefore, a simpler model would have higher bias and lower variance. \n",
    "\n",
    "4. It is important to standardise the data when working with Ridge regression.\n",
    "    \n",
    "5. The model coefficients of ridge regression can shrink very close to 0 but do not become 0 and hence there is no feature selection with ridge regression.\n",
    "\n",
    "Ridge regression does have one obvious disadvantage. It would include all the predictors in the final model. This may not affect the accuracy of the predictions but can make model interpretation challenging when the number of predictors is very large\n",
    "</b>\n",
    "\n",
    "\n",
    "<b> Lasso Regression </b>\n",
    "\n",
    "Cost function for Ridge: $ \\sum \\limits_{i=1} ^{n} (y_{i} - \\hat{y}_{i})^2 + {\\lambda} \\sum \\limits_{j=1} ^{p}  |{\\beta}_{j} | $\n",
    "\n",
    "The primary difference between Lasso and Ridge regression is their penalty term. The penalty term here is the sum of the absolute values of all the coefficients present in the model. As with Ridge regression, Lasso regression shrinks the coefficient estimates towards 0. However, there is one difference. With Lasso, the penalty pushes some of the coefficient estimates to be exactly 0, provided the tuning parameter, λ, is large enough.\n",
    "\n",
    "Hence, Lasso performs feature selection. Choosing an appropriate value of lambda is critical here as well. Because of this, it is easier to interpret models generated by Lasso as compared with those generated by Ridge. Also, just like with Ridge regression, standardisation of variables is necessary for Lasso as well.\n",
    "\n",
    "<b> \n",
    "\n",
    "to summarise:\n",
    "\n",
    "1. The behaviour of Lasso regression is similar to that of Ridge regression.\n",
    "2. With an increase in the value of lambda, variance reduces with a slight compromise in terms of bias.\n",
    "3. Lasso also pushes the model coefficients towards 0 in order to handle high variance, just like Ridge regression. But, in addition to this, Lasso also pushes some coefficients to be exactly 0 and thus performs variable selection.\n",
    "4. This variable selection results in models that are easier to interpret.\n",
    "    \n",
    "</b>\n",
    "\n",
    "Generally, Lasso should perform better in situations where only a few among all the predictors that are used to build our model have a significant influence on the response variable. So, feature selection, which removes the unrelated variables, should help. But Ridge should do better when all the variables have almost the same influence on the response variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "min temp\n",
    "max temp\n",
    "median temp\n",
    "weather feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
